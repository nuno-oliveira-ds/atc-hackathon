{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from haversine import haversine_vector, Unit\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data of places from the Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYKEY = 'AIzaSyDQjEq0NZ3VKqNI4VD7WRmXUtCKOt0xwm4'\n",
    "PLACES = [\n",
    "    'restaurant', 'bar',\n",
    "    'school',\n",
    "    'park',\n",
    "    'bus_station', 'train_station'\n",
    "]\n",
    "PARISHES = [\n",
    "    'gl√≥ria',\n",
    "    'vera cruz',\n",
    "    'aradas'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchPlaces(what, place):\n",
    "    url_base = \"https://maps.googleapis.com/maps/api/place/textsearch/json?\"\n",
    "    url_ext = \"query=\"+what+\",\"+place+\",aveiro&key=\"+MYKEY\n",
    "    url = url_base + url_ext\n",
    "\n",
    "    payload={}\n",
    "    headers = {\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    varResp = response.json()\n",
    "    results = varResp['results']\n",
    "    \n",
    "    # get the info from the second page\n",
    "    if 'next_page_token' in varResp.keys():\n",
    "        time.sleep(5)\n",
    "        urlN = url + \"&pagetoken=\" + varResp['next_page_token']\n",
    "        responseN = requests.request(\"GET\", urlN, headers=headers, data=payload)\n",
    "        varRespN = responseN.json()\n",
    "        results.extend(varRespN['results'])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for place in PARISHES:\n",
    "    for what in PLACES:\n",
    "        print (what + \" - \" + place + \" :  \")\n",
    "        \n",
    "        tmp_result = searchPlaces(what, place)\n",
    "\n",
    "        for result in tmp_result:\n",
    "            tmp_dict = {\n",
    "                'place': what,\n",
    "                'name': result['name'],\n",
    "                'lat': result['geometry']['location']['lat'],\n",
    "                'lon': result['geometry']['location']['lng'],\n",
    "            }\n",
    "            tmp_dict['rating'] = result['rating'] if 'rating' in result.keys() else -100\n",
    "            tmp_dict['user_ratings_total'] = result['user_ratings_total'] if 'user_ratings_total' in result.keys() else -100\n",
    "            tmp_dict['price_level'] = result['price_level'] if 'price_level' in result.keys() else -100\n",
    "            \n",
    "            results.append(tmp_dict)\n",
    "\n",
    "df_places = pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_places = df_places\\\n",
    "    .drop_duplicates()\\\n",
    "    .groupby(['name', 'lat', 'lon']).filter(lambda x: len(x) == 1)\\\n",
    "    .reset_index(drop=True)\n",
    "    \n",
    "df_places['p1'], df_places['p3'], df_places['p35'] = [0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count how many places there are within a 250 meter radius of each pole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLES = {\n",
    "    'p1': (40.63476, -8.66038),\n",
    "    'p3': (40.64074, -8.65705),\n",
    "    'p35': (40.63028, -8.65423)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the distance between two points in meters\n",
    "def calculate_dist(post, lat, lon):\n",
    "    point_x = (lat, lon)\n",
    "\n",
    "    return haversine_vector([POLES[post]], [point_x], Unit.METERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifies places that are within a 250 meters radius of a pole \n",
    "for index, row in df_places.iterrows():\n",
    "    lat = row['lat']\n",
    "    lon = row['lon']\n",
    "\n",
    "    for pole in POLES:\n",
    "        if calculate_dist(pole, lat, lon)[0] <= 250:\n",
    "            df_places.at[index, pole] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts how many places there are associated with each pole\n",
    "df_places_agg = df_places.groupby('place').agg({'p1': sum, 'p3': sum, 'p35':sum})\n",
    "df_places_agg = df_places_agg\\\n",
    "    .T\\\n",
    "    .reset_index()\\\n",
    "    .rename_axis(None, axis=1)\\\n",
    "    .rename(\n",
    "        columns = {\n",
    "            'index': 'n_p',\n",
    "            'restaurant': 'n_rest',\n",
    "            'bar': 'n_bar',\n",
    "            'school': 'n_school',\n",
    "            'park': 'n_park'\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df with the places that are at least close to one pole\n",
    "df_placesNearPoles = df_places[\n",
    "    (df_places['p1'] == 1) |\n",
    "    (df_places['p3'] == 1) |\n",
    "    (df_places['p35'] == 1) \n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add this info to the existing indicator database\n",
    "df_indicator = pd.read_parquet('s3://datalake-eu-central-1/ugiO-atchackathon/preprocessed/indicator_regression.parquet')\n",
    "df_indicator = df_indicator\\\n",
    "    .reset_index()\\\n",
    "    .merge(df_places_agg, on='n_p')\\\n",
    "    .set_index('time_index')\n",
    "\n",
    "df_indicator[\"n_points_of_interest\"] = df_indicator[[\"n_bar\", \"n_park\", \"n_rest\", \"n_school\"]].sum(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframes\n",
    "df_indicator.to_parquet('s3://datalake-eu-central-1/ugiO-atchackathon/preprocessed/indicator_regression_plus_places.parquet')\n",
    "df_places.to_parquet('../databases/allPlaces.parquet')\n",
    "df_placesNearPoles.to_parquet('../databases/placesNearPoles.parquet')\n",
    "df_places_agg.to_parquet('../databases/placesAgg.parquet')\n",
    "df_indicator.to_parquet('../databases/indicatorPlusPlaces.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indicator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('atcenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62faac2f919e037b184b53b7087d230fea4502c81517a8a64786f311e9979a0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
